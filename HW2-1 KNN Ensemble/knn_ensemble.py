# -*- coding: utf-8 -*-
"""KNN-Ensemble.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UGt4v3UaZMr86w-4hVlA0UMwbFgFuNQI

<img src="./pic/sharif-main-logo.png" alt="SUT logo" width=345 height=345 align=left class="saturate">


<br>
<font>
<div dir=ltr align=center>
<font color=0F5298 size=7>
    Machine Learning <br>
<font color=2565AE size=5>
    Computer Engineering Department <br>
    Fall 2024<br>
<font color=3C99D size=5>
    Practical Assignment 2 - Unsupervised Learning<br>
<font color=696880 size=4>
    Assignment Supervisor: Niki Sepasian <br>
<font color=696880 size=5>
    Sarina Heshmati
"""

student_number = "400105433"
full_name = "Sina Beyrami"
assert student_number and full_name is not None, 'please input your information'

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Configure visualizations
sns.set(style="whitegrid")

"""## Overview

In this assignment, you will explore a dataset containing information about employees and use that data to train models capable of predicting whether those employees have left the company (attrited) or not. You will start by exploring the dataset, analyzing its features, and performing necessary preprocessing steps (such as label encoding and scaling). Then, you will build and evaluate implementations of K-Nearest Neighbors (KNN) as well as Random Forest, Bagging, and AdaBoost classifiers. After training and tuning each model, you’ll compare their performance using metrics like accuracy and feature importance to identify the best approach for accurate attrition prediction.

# Load and Explore Dataset (10 points)
"""

import pandas as pd

# Load the dataset
# "Attrition" is our target columm

df = pd.read_csv('dataset.csv')
df.head(5)

"""Explore the dataset and get familiar with its features and statistics. (don't worry about the 'masked values' in our target column. They are simply used to automatically test your model later on.)"""

# TODO: Check the basic structure of the dataset using .info() and .describe()
# Use: df.info() to check data types and missing values
df.info()
print("-"*20)
# Use: df.describe() to get summary statistics of numeric features
print(df.describe())
print("-"*20)

# TODO: Check for any missing values in the dataset
# Use: df.isnull().sum() to find if any column has missing values
missing_values = df.isnull().sum()
print("Missing values in each column:\n", missing_values)
print("-"*20)

# TODO: Explore the target variable (binary classification)
# Use value_counts() to see the distribution of our target (Attrition) column and then visualize it (bar plot).
target_distribution = df['Attrition'].value_counts()
print("Target variable distribution:\n", target_distribution)

plt.figure(figsize=(6, 4))
sns.barplot(x=target_distribution.index, y=target_distribution.values)
plt.title("Distribution of Target Variable (Attrition)")
plt.xlabel("Attrition")
plt.ylabel("Count")
plt.show()

df.head()

"""It is generally better to remove columns with only one unique value from a DataFrame when preparing data for a decision tree. <br>
Such columns do not provide any useful information for splitting the data and can lead to unnecessary complexity in the model. Remove the said columns from the DataFrame.
"""

# TODO Measure and print the number of unique values for each column.
unique_values = {column: df[column].nunique() for column in df.columns}
print("Unique values per column:", unique_values)

# Check if there are any columns with less than 2 unique values. If so, remove them.
columns_to_drop = [column for column, unique_count in unique_values.items() if unique_count < 2]
df = df.drop(columns=columns_to_drop)

print("Columns removed:", columns_to_drop)
print("DataFrame shape after removal:", df.shape)

"""Look at the DataFrame and try to gather insight into people's monthly income and things that generally affect this number."""

# TODO: Plot (lineplot) the average MonthlyIncome against the YearsAtCompany.

plt.figure(figsize=(10, 6))
sns.lineplot(data=df, x='YearsAtCompany', y='MonthlyIncome', estimator='mean', errorbar=None)
plt.title('Average Monthly Income vs. Years at Company')
plt.xlabel('Years at Company')
plt.ylabel('Average Monthly Income')
plt.show()

# TODO: Then find which departments have the highest and lowest incomes on average.

department_income = df.groupby('Department')['MonthlyIncome'].mean()
highest_income_department = department_income.idxmax()
lowest_income_department = department_income.idxmin()

print("\n\nDepartment with highest average income:", highest_income_department, "-", department_income[highest_income_department])
print("Department with lowest average income:", lowest_income_department, "-", department_income[lowest_income_department])

"""# Data Preprocessing (5 points)

Label Encode categorical columns and create a new DataFrame. Then split this data into train and test.
"""

# TODO: Label encode all categorical columns
encoded_df = df.copy()
label_encoders = {}
for column in encoded_df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    encoded_df[column] = le.fit_transform(encoded_df[column])
    label_encoders[column] = le

encoded_df.head()

# Split into features and target variable
X = encoded_df.drop(columns=['Attrition'])
y = encoded_df['Attrition']

# TODO: Perform a train-test split using train_test_split() from sklearn
# Split the dataset into training and test sets with a test size of 30%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# TODO: Scale the features using StandardScaler
# Fit the scaler on the training data and transform both the training and test sets
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print(X_train[:5])

"""# K-Nearest Neighbors (KNN) Model (15 points)

Implement KNN model from scratch.
"""

import numpy as np
from collections import Counter

class CustomKNN:
    def __init__(self, k):
        """
        Initialize the KNN classifier.

        Parameters:
        - k (int): Number of neighbors to consider.
        """
        # Store the number of neighbors (k)
        self.k = k

    def fit(self, X_train, y_train):
        """
        Fit the KNN classifier to the training data.

        Parameters:
        - X_train (numpy array): Training feature vectors.
        - y_train (numpy array): Training labels.
        """
        # Store training data
        self.X_train = np.array(X_train)
        self.y_train = np.array(y_train)

    def euclidean_distance(self, x1, x2):
        """
        Calculate the Euclidean distance between two data points.

        Parameters:
        - x1 (numpy array): First data point.
        - x2 (numpy array): Second data point.

        Returns:
        - float: Euclidean distance between x1 and x2.
        """
        # TODO: Calculate and return the Euclidean distance
        return np.sqrt(np.sum((x1 - x2) ** 2))

    def predict(self, X_test):
        """
        Predict labels for test data.

        Parameters:
        - X_test (numpy array): Test feature vectors.

        Returns:
        - numpy array: Predicted labels.
        """
        # TODO: Predict label for each test instance and return the array of predictions
        predictions = [self._predict(x) for x in X_test]
        return np.array(predictions)

    def _predict(self, x):
        """
        Predict label for a single data point.

        Parameters:
        - x (numpy array): Test data point.

        Returns:
        - int: Predicted label.
        """
        # TODO: Compute distances from x to all training points.
        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]
        # Find the indices and labels of k nearest neighbors.
        k_indices = np.argsort(distances)[:self.k]
        k_nearest_labels = [self.y_train[i] for i in k_indices]
        # Perform mafority vote and return the most common label among them.
        most_common = Counter(k_nearest_labels).most_common(1)
        return most_common[0][0]

"""Fit and test your model using different k values and then choose the best one."""

# Optional. You can choose any range of k values that you want.
k_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
accuracies = []

best_accuracy = 0
Best_custom_model = None
bestk = None

for k in k_values:
    y_pred_custom= []

    # TODO: Fit the model using the scaled training data
    model = CustomKNN(k=k)
    model.fit(X_train, y_train)
    # TODO: Make predictions on the scaled test data
    y_pred_custom = model.predict(X_test)
    # TODO: Evaluate the model's accuracy for each value of k and choose the best one
    accuracy = accuracy_score(y_test, y_pred_custom)
    accuracies.append(accuracy)

    print(f'k: {k} - Accuracy: {accuracy}')

    if accuracy > best_accuracy:
        best_accuracy = accuracy
        Best_custom_model = model
        bestk = k

print("\nBest k value:", bestk)
print("Best accuracy:", best_accuracy)

# TODO: Print the accuracy and classification report using sklearn's metrics for your best model
y_pred_best = Best_custom_model.predict(X_test)
print(f"Accuracy for the best model (k={bestk}): {accuracy_score(y_test, y_pred_best)}")
print("Classification Report for the best model:")
print(classification_report(y_test, y_pred_best))

"""Visualize the confusion matrix for KNN predictions"""

# TODO: Create a confusion matrix for KNN predictions
# Use confusion_matrix from sklearn.metrics
conf_matrix = confusion_matrix(y_test, y_pred_best)

# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title(f"Confusion Matrix for KNN Model (k={bestk})")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

"""## Evaluation (30 points)
In this part, we are going to evaluate your model's performance on another set of unseen data. Load test.csv (this data is already encoded), use your best_custom_model to predict and save the results in a DataFrame called 'result.csv'. The DataFrame should contain one column called 'target' that contains your model's predictions.
"""

# Load test.csv
eval_df= pd.read_csv('test.csv')

# TODO: Use your old scaler to scale the data
eval_df = scaler.fit_transform(eval_df)
# TODO: Predict using your model

y_pred_eval= Best_custom_model.predict(eval_df)

"""Save the results in a DataFrame"""

# Save the results as a csv file
result_df= pd.DataFrame()
result_df['target']=pd.Series(y_pred_eval)
result_df.to_csv('result.csv', index= False)

"""# Random Forest Model (12 points)

Implement a random forest model using sklearn.
"""

# TODO: Implement the Random Forest model
rf = RandomForestClassifier(random_state=42)

# TODO: Set up a hyperparameter tuning process for Random Forest using GridSearchCV
# Suggested parameter grid: {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10]}
param_grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10]}

# GridSearchCV with Random Forest
rf_cv = GridSearchCV(rf, param_grid_rf, cv=5)

# TODO: Fit the GridSearchCV on the training data to find the best parameters
# Use rf_cv.fit() with the training data
rf_cv.fit(X_train, y_train)

# TODO: Use the best Random Forest model for predictions on the test data
# Use rf_cv.best_estimator_ and predict()
best_rf = rf_cv.best_estimator_
y_pred = best_rf.predict(X_test)

# TODO: Print the Random Forest model accuracy and classification report using sklearn's metrics
# Use accuracy_score and classification_report
rf_accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"Random Forest Model Accuracy: {rf_accuracy}")
print("Classification Report:")
print(report)

"""Visualize the confusion matrix for Random Forest predictions"""

# TODO: Create a confusion matrix for Random Forest predictions
# Use confusion_matrix from sklearn.metrics
rf_conf_matrix = confusion_matrix(y_test, y_pred)

# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability
plt.figure(figsize=(8, 6))
sns.heatmap(rf_conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title(f"Confusion Matrix for Random Forest Model")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

"""A feature importance plot is a visual representation that illustrates the significance of each feature (or variable) in a machine learning model, particularly in the context of supervised learning tasks like classification and regression. Plot the feature importances using a bar plot."""

# Get the feature importances from the trained Random Forest model
importances= best_rf.feature_importances_

# TODO: Sort the indices of the importance values in descending order
indices = importances.argsort()[::-1]

feature_names = X.columns

# TODO: Create a DataFrame that contains the feature names and their corresponding importance scores
feature_importances = pd.DataFrame({
    'Feature': [feature_names[i] for i in indices],
    'Importance': importances[indices]
})

# TODO: Create a bar plot to visualize feature importances using Seaborn
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importances)

# use tick_params and Rotate the x-axis labels for better readability
plt.tick_params(axis='x', rotation=45)
plt.title("Feature Importances in Random Forest Model")
plt.xlabel("Importance Score")
plt.ylabel("Feature")

plt.show()

"""# Bagging with KNN (12 points)"""

# TODO: Implement Bagging with KNN
# Use BaggingClassifier with KNeighborsClassifier as the base estimator
# Here we use the bestk value we found before

bagging_knn = BaggingClassifier(KNeighborsClassifier(n_neighbors=bestk), n_estimators=50, random_state=42)

# TODO: Fit the BaggingClassifier on the scaled training data
# Use bagging_knn.fit() with the training data
bagging_knn.fit(X_train, y_train)

# TODO: Use the trained Bagging model for predictions on the test data
# Use bagging_knn.predict()
y_pred = bagging_knn.predict(X_test)


# TODO: Print the Bagging KNN model accuracy and classification report
# Use accuracy_score and classification_report
bag_accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"Bagging KNN Model Accuracy: {bag_accuracy}")
print("Classification Report:")
print(report)

"""Visualize the confusion matrix for Baggin KNN predictions"""

# TODO: Create a confusion matrix for Bagging KNN predictions
# Use confusion_matrix from sklearn.metrics
bag_conf_matrix = confusion_matrix(y_test, y_pred)

# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability
plt.figure(figsize=(8, 6))
sns.heatmap(bag_conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title(f"Confusion Matrix for Bagging KNN Model (k={bestk})")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

"""# AdaBoost Model (12 points)"""

# TODO: Implement AdaBoost model
adaboost = AdaBoostClassifier(random_state=42, algorithm='SAMME')

# TODO: Set up a hyperparameter tuning process for AdaBoost using GridSearchCV
# Suggested parameter grid: {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 1.0]}
param_grid_ada = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 1.0]}

# GridSearchCV with AdaBoost
adaboost_cv = GridSearchCV(adaboost, param_grid_ada, cv=5)

# TODO: Fit the GridSearchCV on the training data to find the best parameters
# Use adaboost_cv.fit() with the training data
adaboost_cv.fit(X_train, y_train)

# TODO: Use the best AdaBoost model for predictions on the test data
# Use adaboost_cv.best_estimator_ and predict()
best_adaboost = adaboost_cv.best_estimator_
y_pred = best_adaboost.predict(X_test)

# TODO: Print the AdaBoost model accuracy and classification report using sklearn's metrics
# Use accuracy_score and classification_report
ada_accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"AdaBoost Model Accuracy: {ada_accuracy}")
print("Classification Report:")
print(report)

"""Visualize the confusion matrix for AdaBoost predictions"""

# TODO: Create a confusion matrix for AdaBoost predictions
# Use confusion_matrix from sklearn.metrics
ada_conf_matrix = confusion_matrix(y_test, y_pred)

# TODO: Visualize the confusion matrix using seaborn's heatmap
# Add annotations and a title for better readability
plt.figure(figsize=(8, 6))
sns.heatmap(ada_conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title(f"Confusion Matrix for Adaboost Model")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

"""# Model Comparison (4 points)"""

# TODO: Compare model accuracies for KNN, Random Forest, Bagging KNN, and AdaBoost
# Create a DataFrame with model names and their respective accuracies
model_accuracies = pd.DataFrame({
    'Model': ['KNN', 'Random Forest', 'Bagging KNN', 'AdaBoost'],
    'Accuracy': [best_accuracy, rf_accuracy, bag_accuracy, ada_accuracy]
})

# TODO: Visualize the model comparison using a line plot
# Use seaborn's lineplot to plot model names vs. accuracies
plt.figure(figsize=(8, 6))
sns.lineplot(data=model_accuracies, x='Model', y='Accuracy', marker='o')
plt.title("Model Accuracy Comparison")
plt.xlabel("Model")
plt.ylabel("Accuracy Score")
plt.show()