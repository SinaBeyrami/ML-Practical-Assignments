{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30841,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<font>\n",
        "<div dir=ltr align=center>\n",
        "<img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" width=150 height=150> <br>\n",
        "<font color=0F5298 size=7>\n",
        "    Machine learning <br>\n",
        "<font color=2565AE size=5>\n",
        "    Computer Engineering Department <br>\n",
        "    Fall 2024<br>\n",
        "<font color=3C99D size=5>\n",
        "    Practical Assignment 5 - NLP - Transformer & Bert <br>\n",
        "</div>\n",
        "<div dir=ltr align=center>\n",
        "<font color=0CBCDF size=4>\n",
        "   &#x1F349; Masoud Tahmasbi  &#x1F349;  &#x1F353; Arash Ziyaei &#x1F353;\n",
        "<br>\n",
        "<font color=0CBCDF size=4>\n",
        "   &#x1F335; Amirhossein Akbari  &#x1F335;\n",
        "</div>\n",
        "\n",
        "____"
      ],
      "metadata": {
        "id": "VivaFsd3Q6cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=9999FF size=4>\n",
        "&#x1F388; Full Name : Sina Beyrami\n",
        "<br>\n",
        "<font color=9999FF size=4>\n",
        "&#x1F388; Student Number : 400105433"
      ],
      "metadata": {
        "id": "k15QziPnmC6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=0080FF size=3>\n",
        "This notebook covers two key topics. First, we implement a transformer model from scratch and apply it to a specific task. Second, we fine-tune the BERT model using LoRA for efficient adaptation to a downstream task.\n",
        "</font>\n",
        "<br>\n",
        "\n",
        "**Note:**\n",
        "<br>\n",
        "<font color=66B2FF size=2>In this notebook, you are free to use any function or model from PyTorch to assist with the implementation. However, TensorFlow is not permitted for this exercise. This ensures consistency and alignment with the tools being focused on.</font>\n",
        "<br>\n",
        "<font color=red size=3>**Run All Cells Before Submission**</font>: <font color=FF99CC size=2>Before saving and submitting your notebook, please ensure you run all cells from start to finish. This practice guarantees that your notebook is self-consistent and can be evaluated correctly by others.</font>"
      ],
      "metadata": {
        "id": "IOfpEN2xmbN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Transformer\n",
        "\n",
        "The transformer architecture consists of two main components: an encoder and a decoder. Each of these components is made up of multiple layers that include self-attention mechanisms and feedforward neural networks. The self-attention mechanism is central to the transformer, as it enables the model to assess the importance of different words in a sentence by considering their relationships with one another.\n",
        "\n",
        "\n",
        "In this assignment, you should design a transformer model from scratch. You are required to implement the Encoder and Decoder components of a Transformer model."
      ],
      "metadata": {
        "id": "SpvvM0995ieR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdrmH20t_uOQ",
        "outputId": "03ef39ef-1a71-4d9c-ec8f-c52af69225fc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:23.607481Z",
          "iopub.execute_input": "2025-01-17T01:36:23.607779Z",
          "iopub.status.idle": "2025-01-17T01:36:27.939088Z",
          "shell.execute_reply.started": "2025-01-17T01:36:23.607752Z",
          "shell.execute_reply": "2025-01-17T01:36:27.938232Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Math\n",
        "import math\n",
        "\n",
        "# HuggingFace libraries\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "# Pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "# typing\n",
        "from typing import Any\n",
        "\n",
        "# Library for progress bars in loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Importing library of warnings\n",
        "import warnings"
      ],
      "metadata": {
        "id": "dzIob6-Gq7Lw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:27.940455Z",
          "iopub.execute_input": "2025-01-17T01:36:27.940715Z",
          "iopub.status.idle": "2025-01-17T01:36:44.746427Z",
          "shell.execute_reply.started": "2025-01-17T01:36:27.940694Z",
          "shell.execute_reply": "2025-01-17T01:36:44.745488Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Input Embeddings\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we observe the Transformer architecture image above, we can see that the Embeddings represent the first step of both blocks.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>InputEmbedding</code> class below is responsible for converting the input text into numerical vectors of <code>d_model</code> dimensions. To prevent that our input embeddings become extremely small, we normalize them by multiplying them by the $\\sqrt{d_{model}}$.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the image below, we can see how the embeddings are created. First, we have a sentence that gets split into tokens—we will explore what tokens are later on—. Then, the token IDs—identification numbers—are transformed into the embeddings, which are high-dimensional vectors.</p>"
      ],
      "metadata": {
        "id": "-71SfIAJprox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a class `InputEmbeddings` inheriting from `nn.Module`\n",
        "# - Initialize the class with two parameters:\n",
        "#   1. `d_model`: Dimension of the embedding vectors\n",
        "#   2. `vocab_size`: Size of the vocabulary\n",
        "# - Create an embedding layer using `nn.Embedding` to map input indices to dense vectors\n",
        "\n",
        "# - In the `forward` method:\n",
        "#   1. Pass the input `x` through the embedding layer\n",
        "#   2. Scale the embeddings by the square root of `d_model` for variance normalization\n",
        "\n",
        "class InputEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embed(x) * math.sqrt(self.d_model)\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "J-pyrJlu4Nl7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.748147Z",
          "iopub.execute_input": "2025-01-17T01:36:44.748977Z",
          "iopub.status.idle": "2025-01-17T01:36:44.753530Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.748952Z",
          "shell.execute_reply": "2025-01-17T01:36:44.752712Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: positional encoding\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the original paper, the authors add the positional encodings to the input embeddings at the bottom of both the encoder and decoder blocks so the model can have some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension $d_{model}$ as the embeddings, so that the two vectors can be summed and we can combine the semantic content from the word embeddings and positional information from the positional encodings.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>PositionalEncoding</code> class below, we will create a matrix of positional encodings <code>pe</code> with dimensions <code>(seq_len, d_model)</code>. We will start by filling it with $0$s.We will then apply the sine function to even indices of the positional encoding matrix while the cosine function is applied to the odd ones.</p>\n",
        "\n",
        "<p style=\"\n",
        "    margin-bottom: 5;\n",
        "    font-size: 22px;\n",
        "    font-weight: 300;\n",
        "    font-family: 'Helvetica Neue', sans-serif;\n",
        "    color: #000000;\n",
        "  \">\n",
        "    \\begin{equation}\n",
        "    \\text{Odd Indices } (2i + 1): \\quad \\text{PE(pos, } 2i + 1) = \\cos\\left(\\frac{\\text{pos}}{10000^{2i / d_{model}}}\\right)\n",
        "    \\end{equation}\n",
        "</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We apply the sine and cosine functions because it allows the model to determine the position of a word based on the position of other words in the sequence, since for any fixed offset $k$, $PE_{pos + k}$ can be represented as a linear function of $PE_{pos}$. This happens due to the properties of sine and cosine functions, where a shift in the input results in a predictable change in the output.</p>"
      ],
      "metadata": {
        "id": "RWBlo2XorJGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `PositionalEncoding` class inheriting from `nn.Module`\n",
        "# - Initialize with `d_model`, `seq_len`, and `dropout`\n",
        "# - Generate a positional encoding matrix using sine and cosine functions\n",
        "# - Register the positional encoding as a non-trainable buffer\n",
        "# - In `forward`, add positional encoding to input and apply dropout\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, seq_len, dropout):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "4ZG5DhVcrVVm",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.754970Z",
          "iopub.execute_input": "2025-01-17T01:36:44.755506Z",
          "iopub.status.idle": "2025-01-17T01:36:44.773993Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.755471Z",
          "shell.execute_reply": "2025-01-17T01:36:44.773390Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: layer normalization\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we look at the encoder and decoder blocks, we see several normalization layers called <b><i>Add &amp; Norm</i></b>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>LayerNormalization</code> class below performs layer normalization on the input data. During its forward pass, we compute the mean and standard deviation of the input data. We then normalize the input data by subtracting the mean and dividing by the standard deviation plus a small number called epsilon to avoid any divisions by zero. This process results in a normalized output with a mean 0 and a standard deviation 1.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will then scale the normalized output by a learnable parameter <code>alpha</code> and add a learnable parameter called <code>bias</code>. The training process is responsible for adjusting these parameters. The final result is a layer-normalized tensor, which ensures that the scale of the inputs to layers in the network is consistent.</p>"
      ],
      "metadata": {
        "id": "T92iydQErh-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `LayerNormalization` class inheriting from `nn.Module`\n",
        "# - Initialize with `eps` (small value to prevent division by zero)\n",
        "# - Define trainable parameters:\n",
        "#   1. `alpha`: Scaling factor initialized to 1\n",
        "#   2. `bias`: Offset initialized to 0\n",
        "\n",
        "# - In `forward`, perform layer normalization:\n",
        "#   1. Compute mean and standard deviation along the last dimension\n",
        "#   2. Normalize the input using the computed mean and std\n",
        "#   3. Scale and shift using `alpha` and `bias`\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.alpha = nn.Parameter(torch.ones(1))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std = x.std(dim=-1, keepdim=True)\n",
        "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "kVGQRsmKrwZu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.774673Z",
          "iopub.execute_input": "2025-01-17T01:36:44.774963Z",
          "iopub.status.idle": "2025-01-17T01:36:44.789868Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.774943Z",
          "shell.execute_reply": "2025-01-17T01:36:44.789266Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Feed Forward Network\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the fully connected feed-forward network, we apply two linear transformations with a ReLU activation in between. We can mathematically represent this operation as:</p>\n",
        "\n",
        "<p style=\"\n",
        "    margin-bottom: 5;\n",
        "    font-size: 22px;\n",
        "    font-weight: 300;\n",
        "    font-family: 'Helvetica Neue', sans-serif;\n",
        "    color: #000000;\n",
        "  \">\n",
        "    \\begin{equation}\n",
        "    \\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2\n",
        "    \\end{equation}\n",
        "</p>\n",
        "\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">$W_1$ and $W_2$ are the weights, while $b_1$ and $b_2$ are the biases of the two linear transformations.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>FeedForwardBlock</code> below, we will define the two linear transformations—<code>self.linear_1</code> and <code>self.linear_2</code>—and the inner-layer <code>d_ff</code>. The input data will first pass through the <code>self.linear_1</code> transformation, which increases its dimensionality from <code>d_model</code> to <code>d_ff</code>. The output of this operation passes through the ReLU activation function, which introduces non-linearity so the network can learn more complex patterns, and the <code>self.dropout</code> layer is applied to mitigate overfitting. The final operation is the <code>self.linear_2</code> transformation to the dropout-modified tensor, which transforms it back to the original <code>d_model</code> dimension.</p>"
      ],
      "metadata": {
        "id": "U-IbSGQMr1Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `FeedForwardBlock` class inheriting from `nn.Module`\n",
        "# - Initialize with `d_model`, `d_ff`, and `dropout`\n",
        "# - Define:\n",
        "#   1. `linear_1`: Linear layer projecting from `d_model` to `d_ff`\n",
        "#   2. Dropout layer for regularization\n",
        "#   3. `linear_2`: Linear layer projecting back from `d_ff` to `d_model`\n",
        "\n",
        "# - In `forward`, apply the following steps:\n",
        "#   1. Pass input through `linear_1` followed by ReLU activation\n",
        "#   2. Apply dropout\n",
        "#   3. Pass through `linear_2` to return to original dimensions\n",
        "\n",
        "class FeedForwardBlock(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "N3H8kyccsEUW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.790514Z",
          "iopub.execute_input": "2025-01-17T01:36:44.790700Z",
          "iopub.status.idle": "2025-01-17T01:36:44.800508Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.790684Z",
          "shell.execute_reply": "2025-01-17T01:36:44.799819Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Multi Head Attention\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The Multi-Head Attention is the most crucial component of the Transformer. It is responsible for helping the model to understand complex relationships and patterns in the data.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The image below displays how the Multi-Head Attention works. It doesn't include <code>batch</code> dimension because it only illustrates the process for one single sentence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The Multi-Head Attention block receives the input data split into queries, keys, and values organized into matrices $Q$, $K$, and $V$. Each matrix contains different facets of the input, and they have the same dimensions as the input.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We then linearly transform each matrix by their respective weight matrices $W^Q$, $W^K$, and $W^V$. These transformations will result in new matrices $Q'$, $K'$, and $V'$, which will be split into smaller matrices corresponding to different heads $h$, allowing the model to attend to information from different representation subspaces in parallel. This split creates multiple sets of queries, keys, and values for each head.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Finally, we concatenate every head into an $H$ matrix, which is then transformed by another weight matrix $W^o$ to produce the multi-head attention output, a matrix $MH-A$ that retains the input dimensionality.</p>"
      ],
      "metadata": {
        "id": "YEa1kF6csIvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `MultiHeadAttentionBlock` class inheriting from `nn.Module`\n",
        "# - Initialize with `d_model` (model dimensions), `h` (number of heads), and `dropout`:\n",
        "#   1. Assert `d_model` is divisible by `h`\n",
        "#   2. Define `d_k` as dimensions per head\n",
        "#   3. Create weight matrices (`w_q`, `w_k`, `w_v`, `w_o`) for query, key, value, and output\n",
        "#   4. Add a dropout layer for regularization\n",
        "\n",
        "# - Implement a static `attention` method to:\n",
        "#   1. Compute scaled dot-product attention\n",
        "#   2. Apply mask if provided\n",
        "#   3. Apply softmax and dropout\n",
        "#   4. Return weighted values and attention scores\n",
        "\n",
        "# - In `forward`, perform:\n",
        "#   1. Linear transformation of input into query, key, and value\n",
        "#   2. Split into `h` heads and rearrange dimensions\n",
        "#   3. Compute attention output and scores using `attention`\n",
        "#   4. Combine heads and apply output weight matrix\n",
        "\n",
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model, h, dropout):\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(q, k, v, mask=None, dropout=None):\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(q.size(-1))\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        if dropout is not None:\n",
        "            attn = dropout(attn)\n",
        "        output = torch.matmul(attn, v)\n",
        "        return output, attn\n",
        "\n",
        "    def forward(self, x_q, x_k, x_v, mask=None):\n",
        "        bsz = x_q.size(0)\n",
        "        q = self.w_q(x_q).view(bsz, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        k = self.w_k(x_k).view(bsz, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        v = self.w_v(x_v).view(bsz, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.attention(q, k, v, mask, self.dropout)\n",
        "        output = output.transpose(1, 2).contiguous().view(bsz, -1, self.h * self.d_k)\n",
        "        output = self.w_o(output)\n",
        "        return output, attn\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "6ujcqPp1sOU9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.801160Z",
          "iopub.execute_input": "2025-01-17T01:36:44.801346Z",
          "iopub.status.idle": "2025-01-17T01:36:44.817157Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.801330Z",
          "shell.execute_reply": "2025-01-17T01:36:44.816409Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Residual Connection\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we look at the architecture of the Transformer, we see that each sub-layer, including the <i>self-attention</i> and <i>Feed Forward</i> blocks, adds its output to its input before passing it to the <i>Add &amp; Norm</i> layer. This approach integrates the output with the original input in the <i>Add &amp; Norm</i> layer. This process is known as the skip connection, which allows the Transformer to train deep networks more effectively by providing a shortcut for the gradient to flow through during backpropagation.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>ResidualConnection</code> class below is responsible for this process.</p>"
      ],
      "metadata": {
        "id": "wCaLjCVxsWIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `ResidualConnection` class inheriting from `nn.Module`\n",
        "# - Initialize with `dropout`:\n",
        "#   1. Add a dropout layer for regularization\n",
        "#   2. Include a layer normalization instance\n",
        "\n",
        "# - In `forward`:\n",
        "#   1. Normalize the input using the normalization layer\n",
        "#   2. Pass the normalized input through the sublayer\n",
        "#   3. Apply dropout and add the result back to the original input for residual connection\n",
        "\n",
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "f-bvuGhIsdfu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.819102Z",
          "iopub.execute_input": "2025-01-17T01:36:44.819312Z",
          "iopub.status.idle": "2025-01-17T01:36:44.835303Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.819294Z",
          "shell.execute_reply": "2025-01-17T01:36:44.834606Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7: Encoder\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will now build the encoder. We create the <code>EncoderBlock</code> class, consisting of the Multi-Head Attention and Feed Forward layers, plus the residual connections.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the original paper, the Encoder Block repeats six times. We create the <code>Encoder</code> class as an assembly of multiple <code>EncoderBlock</code>s. We also add layer normalization as a final step after processing the input through all its blocks.</p>"
      ],
      "metadata": {
        "id": "9YYI5vpasdGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create an `EncoderBlock` class inheriting from `nn.Module`\n",
        "# - Initialize with:\n",
        "#   1. `self_attention_block`: Multi-head attention block\n",
        "#   2. `feed_forward_block`: Feed-forward block\n",
        "#   3. `dropout`: Dropout rate for residual connections\n",
        "# - Define two residual connections for:\n",
        "#   1. Self-attention block\n",
        "#   2. Feed-forward block\n",
        "\n",
        "# - In `forward`:\n",
        "#   1. Apply the first residual connection with the self-attention block\n",
        "#   2. Apply the second residual connection with the feed-forward block\n",
        "#   3. Return the updated tensor after both layers\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, h, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        self.residual_self_attention = ResidualConnection(dropout)\n",
        "        self.feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        self.residual_feed_forward = ResidualConnection(dropout)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        x = self.residual_self_attention(x, lambda _x: self.self_attention_block(_x, _x, _x, src_mask)[0])\n",
        "        x = self.residual_feed_forward(x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "fRtppwE1s0-t",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.836625Z",
          "iopub.execute_input": "2025-01-17T01:36:44.836898Z",
          "iopub.status.idle": "2025-01-17T01:36:44.851849Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.836873Z",
          "shell.execute_reply": "2025-01-17T01:36:44.851155Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create an `Encoder` class inheriting from `nn.Module`\n",
        "# - Initialize with:\n",
        "#   1. `layers`: A list of `EncoderBlock` instances\n",
        "#   2. A layer normalization instance for output normalization\n",
        "\n",
        "# - In `forward`:\n",
        "#   1. Pass the input tensor `x` through each `EncoderBlock` in `self.layers`\n",
        "#   2. Apply the mask during each block's forward pass\n",
        "#   3. Normalize the final output and return it\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, h, d_ff, N, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([EncoderBlock(d_model, h, d_ff, dropout) for _ in range(N)])\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "eSq7BZWcs5s1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.852573Z",
          "iopub.execute_input": "2025-01-17T01:36:44.852763Z",
          "iopub.status.idle": "2025-01-17T01:36:44.867315Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.852747Z",
          "shell.execute_reply": "2025-01-17T01:36:44.866700Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 8: Decoder\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Similarly, the Decoder also consists of several DecoderBlocks that repeat six times in the original paper. The main difference is that it has an additional sub-layer that performs multi-head attention with a <i>cross-attention</i> component that uses the output of the Encoder as its keys and values while using the Decoder's input as queries.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">For the Output Embedding, we can use the same <code>InputEmbeddings</code> class we use for the Encoder. You can also notice that the self-attention sub-layer is <i>masked</i>, which restricts the model from accessing future elements in the sequence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will start by building the <code>DecoderBlock</code> class, and then we will build the <code>Decoder</code> class, which will assemble multiple <code>DecoderBlock</code>s.</p>"
      ],
      "metadata": {
        "id": "P0HXE1fH5g0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `DecoderBlock` class inheriting from `nn.Module`\n",
        "# - Initialize with:\n",
        "#   1. `self_attention_block`: Multi-head self-attention block\n",
        "#   2. `cross_attention_block`: Multi-head cross-attention block\n",
        "#   3. `feed_forward_block`: Feed-forward block\n",
        "#   4. `dropout`: Dropout rate\n",
        "# - Define three residual connections for:\n",
        "#   1. Self-attention block\n",
        "#   2. Cross-attention block\n",
        "#   3. Feed-forward block\n",
        "\n",
        "# - In `forward`:\n",
        "#   1. Apply the self-attention block with target mask and residual connection\n",
        "#   2. Apply the cross-attention block with source mask and residual connection\n",
        "#   3. Apply the feed-forward block with residual connection\n",
        "#   4. Return the updated tensor\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, h, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        self.residual_self_attention = ResidualConnection(dropout)\n",
        "        self.cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        self.residual_cross_attention = ResidualConnection(dropout)\n",
        "        self.feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        self.residual_feed_forward = ResidualConnection(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "        x = self.residual_self_attention(x, lambda _x: self.self_attention_block(_x, _x, _x, tgt_mask)[0])\n",
        "        x = self.residual_cross_attention(x, lambda _x: self.cross_attention_block(_x, encoder_output, encoder_output, src_mask)[0])\n",
        "        x = self.residual_feed_forward(x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "V9Aof9mb4PJX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.868097Z",
          "iopub.execute_input": "2025-01-17T01:36:44.868343Z",
          "iopub.status.idle": "2025-01-17T01:36:44.884226Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.868323Z",
          "shell.execute_reply": "2025-01-17T01:36:44.883452Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `Decoder` class inheriting from `nn.Module`\n",
        "# - Initialize with:\n",
        "#   1. `layers`: A list of `DecoderBlock` instances\n",
        "#   2. A layer normalization instance for the final output\n",
        "\n",
        "# - In `forward`:\n",
        "#   1. Pass the input tensor `x` through each `DecoderBlock` in `self.layers`\n",
        "#   2. Provide `encoder_output`, `src_mask`, and `tgt_mask` to each block\n",
        "#   3. Normalize the final output using the layer normalization\n",
        "#   4. Return the normalized output\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, h, d_ff, N, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([DecoderBlock(d_model, h, d_ff, dropout) for _ in range(N)])\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "vwdthvkrtNUM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.885005Z",
          "iopub.execute_input": "2025-01-17T01:36:44.885205Z",
          "iopub.status.idle": "2025-01-17T01:36:44.900508Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.885187Z",
          "shell.execute_reply": "2025-01-17T01:36:44.899800Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">You can see in the Decoder image that after running a stack of <code>DecoderBlock</code>s, we have a Linear Layer and a Softmax function to the output of probabilities. The <code>ProjectionLayer</code> class below is responsible for converting the output of the model into a probability distribution over the <i>vocabulary</i>, where we select each output token from a vocabulary of possible tokens.</p>"
      ],
      "metadata": {
        "id": "Qm4g_8O1tS3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `ProjectionLayer` class inheriting from `nn.Module`\n",
        "# - Initialize with:\n",
        "#   1. `d_model`: Dimension of the model\n",
        "#   2. `vocab_size`: Size of the output vocabulary\n",
        "# - Define a linear layer to project from `d_model` to `vocab_size`\n",
        "\n",
        "# - In `forward`:\n",
        "#   1. Pass the input through the linear layer\n",
        "#   2. Apply log Softmax along the last dimension\n",
        "#   3. Return the log probabilities\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return nn.functional.log_softmax(x, dim=-1)\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "UbWVoNintThN",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.901220Z",
          "iopub.execute_input": "2025-01-17T01:36:44.901433Z",
          "iopub.status.idle": "2025-01-17T01:36:44.917066Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.901415Z",
          "shell.execute_reply": "2025-01-17T01:36:44.916298Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 9: Building the Transformer\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We finally have every component of the Transformer architecture ready. We may now construct the Transformer by putting it all together.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>Transformer</code> class below, we will bring together all the components of the model's architecture.</p>"
      ],
      "metadata": {
        "id": "waCzPEAxtaR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Create a `Transformer` class inheriting from `nn.Module`\n",
        "# - Initialize with:\n",
        "#   1. `encoder`: Encoder module\n",
        "#   2. `decoder`: Decoder module\n",
        "#   3. `src_embed` and `tgt_embed`: Input embeddings for source and target languages\n",
        "#   4. `src_pos` and `tgt_pos`: Positional encodings for source and target languages\n",
        "#   5. `projection_layer`: Linear projection layer for final output\n",
        "\n",
        "# - Define the `encode` method:\n",
        "#   1. Apply source embeddings to input\n",
        "#   2. Add positional encoding\n",
        "#   3. Pass through the encoder with the source mask\n",
        "#   4. Return the encoded representation\n",
        "\n",
        "# - Define the `decode` method:\n",
        "#   1. Apply target embeddings to input\n",
        "#   2. Add positional encoding\n",
        "#   3. Pass through the decoder with encoder output, source mask, and target mask\n",
        "#   4. Return the decoder's output\n",
        "\n",
        "# - Define the `project` method:\n",
        "#   1. Pass decoder output through the projection layer\n",
        "#   2. Apply log Softmax to obtain probabilities\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask=None):\n",
        "        x = self.src_embed(src)\n",
        "        x = self.src_pos(x)\n",
        "        x = self.encoder(x, src_mask)\n",
        "        return x\n",
        "\n",
        "    def decode(self, tgt, memory, src_mask=None, tgt_mask=None):\n",
        "        x = self.tgt_embed(tgt)\n",
        "        x = self.tgt_pos(x)\n",
        "        x = self.decoder(x, memory, src_mask, tgt_mask)\n",
        "        return x\n",
        "\n",
        "    def project(self, x):\n",
        "        return self.projection_layer(x)\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "qXbPW4oCtk2G",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.917885Z",
          "iopub.execute_input": "2025-01-17T01:36:44.918141Z",
          "iopub.status.idle": "2025-01-17T01:36:44.929648Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.918122Z",
          "shell.execute_reply": "2025-01-17T01:36:44.928901Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The architecture is finally ready. We now define a function called <code>build_transformer</code>, in which we define the parameters and everything we need to have a fully operational Transformer model for the task of <b>machine translation</b>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will set the same parameters as in the original paper, <a href = \"https://arxiv.org/pdf/1706.03762.pdf\"><i>Attention Is All You Need</i></a>, where $d_{model}$ = 512, $N$ = 6, $h$ = 8, dropout rate $P_{drop}$ = 0.1, and $d_{ff}$ = 2048.</p>"
      ],
      "metadata": {
        "id": "6znypMaetmRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `build_transformer` function with parameters for:\n",
        "#   1. Vocabulary sizes (`src_vocab_size`, `tgt_vocab_size`)\n",
        "#   2. Sequence lengths (`src_seq_len`, `tgt_seq_len`)\n",
        "#   3. Model dimensions (`d_model`, `d_ff`)\n",
        "#   4. Number of layers (`N`) and heads (`h`)\n",
        "#   5. Dropout rate (`dropout`)\n",
        "\n",
        "# - Create:\n",
        "#   1. Source and target embedding layers\n",
        "#   2. Positional encoding layers for source and target\n",
        "#   3. Encoder blocks with self-attention and feed-forward layers\n",
        "#   4. Decoder blocks with self-attention, cross-attention, and feed-forward layers\n",
        "#   5. Encoder and Decoder modules using the blocks\n",
        "#   6. Projection layer to map decoder output to target vocabulary\n",
        "\n",
        "# - Assemble all components into a `Transformer` instance\n",
        "# - Initialize parameters with Xavier uniform initialization\n",
        "# - Return the initialized Transformer\n",
        "\n",
        "def build_transformer(src_vocab_size, tgt_vocab_size, src_seq_len, tgt_seq_len, d_model=512, d_ff=2048, N=6, h=8, dropout=0.1):\n",
        "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
        "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
        "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "    encoder = Encoder(d_model, h, d_ff, N, dropout)\n",
        "    decoder = Decoder(d_model, h, d_ff, N, dropout)\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "    model = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "bqGnJ6w2twJc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.930339Z",
          "iopub.execute_input": "2025-01-17T01:36:44.930569Z",
          "iopub.status.idle": "2025-01-17T01:36:44.945915Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.930551Z",
          "shell.execute_reply": "2025-01-17T01:36:44.945161Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is now ready to be trained!"
      ],
      "metadata": {
        "id": "Iw7CWf4bt3yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 10: Tokenizer"
      ],
      "metadata": {
        "id": "6_7Z3fEYuTK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Tokenization is a crucial preprocessing step for our Transformer model. In this step, we convert raw text into a number format that the model can process.  </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">There are several Tokenization strategies. We will use the <i>word-level tokenization</i> to transform each word in a sentence into a token.</p>"
      ],
      "metadata": {
        "id": "EDinqTghqr_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <img src = \"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8d5e749c-b0bd-4496-85a1-9b4397ad935f_1400x787.jpeg\" width = 800, height= 800>\n",
        "<p style = \"font-size: 16px;\n",
        "            font-family: 'Georgia', serif;\n",
        "            text-align: center;\n",
        "            margin-top: 10px;\">Different tokenization strategies. Source: <a href = \"https://shaankhosla.substack.com/p/talking-tokenization\">shaankhosla.substack.com</a>.</p>\n",
        "</center>"
      ],
      "metadata": {
        "id": "at-cYYjnqr_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">After tokenizing a sentence, we map each token to an unique integer ID based on the created vocabulary present in the training corpus during the training of the tokenizer. Each integer number represents a specific word in the vocabulary.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Besides the words in the training corpus, Transformers use special tokens for specific purposes. These are some that we will define right away:</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>• [UNK]:</b> This token is used to identify an unknown word in the sequence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>• [PAD]:</b> Padding token to ensure that all sequences in a batch have the same length, so we pad shorter sentences with this token. We use attention masks to <i>\"tell\"</i> the model to ignore the padded tokens during training since they don't have any real meaning to the task.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>•  [SOS]:</b> This is a token used to signal the <i>Start of Sentence</i>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>•  [EOS]:</b> This is a token used to signal the <i>End of Sentence</i>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>build_tokenizer</code> function below, we ensure a tokenizer is ready to train the model. It checks if there is an existing tokenizer, and if that is not the case, it trains a new tokenizer.</p>"
      ],
      "metadata": {
        "id": "gjRMr2N6qr_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `build_tokenizer` function with parameters for:\n",
        "#   1. `config`: Configuration containing tokenizer file path\n",
        "#   2. `ds`: Dataset to train the tokenizer\n",
        "#   3. `lang`: Language for which the tokenizer is built\n",
        "\n",
        "# - Check if the tokenizer file exists:\n",
        "#   1. If not, create a new tokenizer:\n",
        "#      - Initialize a word-level tokenizer with an unknown token (`[UNK]`)\n",
        "#      - Set the pre-tokenizer to split text by whitespace\n",
        "#      - Define a trainer with special tokens and minimum frequency\n",
        "#      - Train the tokenizer on all sentences in the dataset\n",
        "#      - Save the trained tokenizer to the specified file path\n",
        "#   2. If the file exists, load the tokenizer from the file\n",
        "\n",
        "# - Return the loaded or trained tokenizer\n",
        "\n",
        "def build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Path(config['tokenizer_file'].format(lang=lang))\n",
        "    if not tokenizer_path.is_file():\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=['[UNK]', '[PAD]', '[SOS]', '[EOS]'], min_frequency=2)\n",
        "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "Zh9pOItduxHq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.946731Z",
          "iopub.execute_input": "2025-01-17T01:36:44.947012Z",
          "iopub.status.idle": "2025-01-17T01:36:44.962237Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.946985Z",
          "shell.execute_reply": "2025-01-17T01:36:44.961611Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 11: Load Dataset"
      ],
      "metadata": {
        "id": "oodlr4eouxTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">For this task, we will use the <a href = \"opus_books · Datasets at Hugging Face\">OpusBooks dataset</a>, available on 🤗Hugging Face. This dataset consists of two features, <code>id</code> and <code>translation</code>. The <code>translation</code> feature contains pairs of sentences in different languages, such as Spanish and Portuguese, English and French, and so forth.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">I first tried translating sentences from English to Portuguese—my native tongue — but there are only 1.4k examples for this pair, so the results were not satisfying in the current configurations for this model. I then tried to use the English-French pair due to its higher number of examples—127k—but it would take too long to train with the current configurations. I then opted to train the model on the English-Italian pair, the same one used in the <a href = \"https://youtu.be/ISNdQcPhsts?si=253J39cose6IdsLv\">Coding a Transformer from scratch on PyTorch, with full explanation, training and inference\n",
        "</a> video, as that was a good balance between performance and time of training.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We start by defining the <code>get_all_sentences</code> function to iterate over the dataset and extract the sentences according to the language pair defined—we will do that later.</p>"
      ],
      "metadata": {
        "id": "YdVFowgUqr_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `get_all_sentences` function to extract sentences from a dataset\n",
        "# - Accept parameters:\n",
        "#   1. `ds`: The dataset containing translation pairs\n",
        "#   2. `lang`: The language key to extract translations\n",
        "\n",
        "# - Iterate through the dataset:\n",
        "#   1. Access the 'translation' field of each pair\n",
        "#   2. Yield the sentence corresponding to the specified language key\n",
        "\n",
        "def get_all_sentences(ds, lang):\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "xvRuuTpIveZS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.963127Z",
          "iopub.execute_input": "2025-01-17T01:36:44.963359Z",
          "iopub.status.idle": "2025-01-17T01:36:44.976572Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.963335Z",
          "shell.execute_reply": "2025-01-17T01:36:44.975939Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>get_ds</code> function is defined to load and prepare the dataset for training and validation. In this function, we build or load the tokenizer, split the dataset, and create DataLoaders, so the model can successfully iterate over the dataset in batches. The result of these functions is tokenizers for the source and target languages plus the DataLoader objects.</p>"
      ],
      "metadata": {
        "id": "EA13IRYEqr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `get_ds` function to process and prepare the dataset for training\n",
        "# - Load the `OpusBooks` dataset using:\n",
        "#   1. Source and target languages from `config`\n",
        "#   2. Train split of the dataset\n",
        "\n",
        "# - Build or load tokenizers for source and target languages using `build_tokenizer`\n",
        "\n",
        "# - Split the dataset into training and validation sets:\n",
        "#   1. Allocate 90% for training and 10% for validation\n",
        "#   2. Use `random_split` for randomized splitting\n",
        "\n",
        "# - Process the splits using a `BilingualDataset` class:\n",
        "#   1. Convert sentences to tokenized representations\n",
        "#   2. Apply source and target tokenizers\n",
        "#   3. Ensure sequence lengths conform to `config`\n",
        "\n",
        "# - Compute and print the maximum sentence lengths for both source and target languages\n",
        "\n",
        "# - Create DataLoader objects for training and validation:\n",
        "#   1. Define batch sizes from `config`\n",
        "#   2. Enable shuffling for training DataLoader\n",
        "\n",
        "# - Return:\n",
        "#   1. Training DataLoader\n",
        "#   2. Validation DataLoader\n",
        "#   3. Tokenizer for source language\n",
        "#   4. Tokenizer for target language\n",
        "\n",
        "def get_ds(config):\n",
        "    dataset = load_dataset(\"opus_books\", f\"{config['lang_src']}-{config['lang_tgt']}\", split=\"train\")\n",
        "    tokenizer_src = build_tokenizer(config, dataset, config['lang_src'])\n",
        "    tokenizer_tgt = build_tokenizer(config, dataset, config['lang_tgt'])\n",
        "    train_size = int(0.9 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_ds_raw, val_ds_raw = random_split(dataset, [train_size, val_size])\n",
        "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    print(\"Max source length:\", max(len(tokenizer_src.encode(item['translation'][config['lang_src']]).ids) for item in dataset))\n",
        "    print(\"Max target length:\", max(len(tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids) for item in dataset))\n",
        "    train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "    return train_loader, val_loader, tokenizer_src, tokenizer_tgt\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "IkTRqP8LvpVy",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.977357Z",
          "iopub.execute_input": "2025-01-17T01:36:44.977639Z",
          "iopub.status.idle": "2025-01-17T01:36:44.991055Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.977613Z",
          "shell.execute_reply": "2025-01-17T01:36:44.990402Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We define the <code>casual_mask</code> function to create a mask for the attention mechanism of the decoder. This mask prevents the model from having information about future elements in the sequence. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We start by making a square grid filled with ones. We determine the grid size with the <code>size</code> parameter. Then, we change all the numbers above the main diagonal line to zeros. Every number on one side becomes a zero, while the rest remain ones. The function then flips all these values, turning ones into zeros and zeros into ones. This process is crucial for models that predict future tokens in a sequence.</p>"
      ],
      "metadata": {
        "id": "VK3d2-AVqr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `casual_mask` function to create an upper triangular mask\n",
        "# - Accept `size` as the dimension of the square matrix\n",
        "# - Steps:\n",
        "#   1. Create a square matrix of size `size x size` filled with ones\n",
        "#   2. Use `torch.triu` to make it upper triangular, with zeros below the diagonal\n",
        "#   3. Convert the matrix to integer type\n",
        "#   4. Return the mask where zeros represent the causal positions\n",
        "\n",
        "def casual_mask(size):\n",
        "    mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
        "    mask = (mask == 0)\n",
        "    return mask\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "kTgMYaY2vvWq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:44.991786Z",
          "iopub.execute_input": "2025-01-17T01:36:44.992015Z",
          "iopub.status.idle": "2025-01-17T01:36:45.006171Z",
          "shell.execute_reply.started": "2025-01-17T01:36:44.991998Z",
          "shell.execute_reply": "2025-01-17T01:36:45.005445Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>BilingualDataset</code> class processes the texts of the target and source languages in the dataset by tokenizing them and adding all the necessary special tokens. This class also certifies that the sentences are within a maximum sequence length for both languages and pads all necessary sentences.</p>"
      ],
      "metadata": {
        "id": "ccdK5XnMqr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `BilingualDataset` class inheriting from `Dataset`\n",
        "# - Initialize with:\n",
        "#   1. `ds`: Dataset containing sentence pairs\n",
        "#   2. `tokenizer_src` and `tokenizer_tgt`: Tokenizers for source and target languages\n",
        "#   3. `src_lang` and `tgt_lang`: Language identifiers\n",
        "#   4. `seq_len`: Maximum sequence length for tokens\n",
        "\n",
        "# - Define special tokens (`[SOS]`, `[EOS]`, `[PAD]`) using the target tokenizer\n",
        "\n",
        "# - Implement `__len__` to return the number of sentence pairs in the dataset\n",
        "\n",
        "# - Implement `__getitem__` to:\n",
        "#   1. Retrieve source and target texts based on the index\n",
        "#   2. Tokenize source and target texts\n",
        "#   3. Compute required padding for source and target tokens\n",
        "#   4. Raise an error if tokenized sentences exceed `seq_len`\n",
        "#   5. Build `encoder_input` by concatenating `[SOS]`, tokenized text, `[EOS]`, and padding\n",
        "#   6. Build `decoder_input` by concatenating `[SOS]`, tokenized text, and padding\n",
        "#   7. Build `label` by concatenating tokenized text, `[EOS]`, and padding\n",
        "#   8. Ensure all tensors are of length `seq_len`\n",
        "\n",
        "# - Return a dictionary containing:\n",
        "#   1. `encoder_input`: Tensor for the encoder\n",
        "#   2. `decoder_input`: Tensor for the decoder\n",
        "#   3. `encoder_mask`: Mask for non-padding tokens in the encoder\n",
        "#   4. `decoder_mask`: Mask for non-padding tokens in the decoder with causal masking\n",
        "#   5. `label`: Expected output for training\n",
        "#   6. `src_text` and `tgt_text`: Original source and target texts\n",
        "\n",
        "class BilingualDataset(Dataset):\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n",
        "        self.ds = ds\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "        self.seq_len = seq_len\n",
        "        self.sos_id = self.tokenizer_tgt.token_to_id('[SOS]')\n",
        "        self.eos_id = self.tokenizer_tgt.token_to_id('[EOS]')\n",
        "        self.pad_id = self.tokenizer_tgt.token_to_id('[PAD]')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.ds[idx]\n",
        "        src_text = item['translation'][self.src_lang]\n",
        "        tgt_text = item['translation'][self.tgt_lang]\n",
        "        src_ids = self.tokenizer_src.encode(src_text).ids\n",
        "        tgt_ids = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "        if len(src_ids) + 2 > self.seq_len:\n",
        "            src_ids = src_ids[: self.seq_len - 2]\n",
        "        if len(tgt_ids) + 2 > self.seq_len:\n",
        "            tgt_ids = tgt_ids[: self.seq_len - 2]\n",
        "\n",
        "        encoder_input = [self.sos_id] + src_ids + [self.eos_id]\n",
        "        decoder_input = [self.sos_id] + tgt_ids\n",
        "        label = tgt_ids + [self.eos_id]\n",
        "\n",
        "        encoder_input += [self.pad_id] * (self.seq_len - len(encoder_input))\n",
        "        decoder_input += [self.pad_id] * (self.seq_len - len(decoder_input))\n",
        "        label += [self.pad_id] * (self.seq_len - len(label))\n",
        "\n",
        "        encoder_input = torch.tensor(encoder_input, dtype=torch.long)\n",
        "        decoder_input = torch.tensor(decoder_input, dtype=torch.long)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'encoder_input': encoder_input,\n",
        "            'decoder_input': decoder_input,\n",
        "            'label': label,\n",
        "            'src_text': src_text,\n",
        "            'tgt_text': tgt_text\n",
        "        }\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "x9v94mdgv3y6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:45.006996Z",
          "iopub.execute_input": "2025-01-17T01:36:45.007181Z",
          "iopub.status.idle": "2025-01-17T01:36:45.019408Z",
          "shell.execute_reply.started": "2025-01-17T01:36:45.007165Z",
          "shell.execute_reply": "2025-01-17T01:36:45.018662Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 12: Validation Loop"
      ],
      "metadata": {
        "id": "B7cXlNUfv5uL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will now create two functions for the validation loop. The validation loop is crucial to evaluate model performance in translating sentences from data it has not seen during training.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will define two functions. The first function, <code>greedy_decode</code>, gives us the model's output by obtaining the most probable next token. The second function, <code>run_validation</code>, is responsible for running the validation process in which we decode the model's output and compare it with the reference text for the target sentence.</p>"
      ],
      "metadata": {
        "id": "tf8Wt860qr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `greedy_decode` function to generate the most probable sequence using a trained model\n",
        "# - Accept parameters:\n",
        "#   1. `model`: Trained Transformer model\n",
        "#   2. `source`: Source input sequence\n",
        "#   3. `source_mask`: Mask for the source sequence\n",
        "#   4. `tokenizer_src` and `tokenizer_tgt`: Tokenizers for source and target languages\n",
        "#   5. `max_len`: Maximum sequence length for the output\n",
        "#   6. `device`: Device to run the computation (e.g., CPU or GPU)\n",
        "\n",
        "# - Steps:\n",
        "#   1. Retrieve indices for `[SOS]` and `[EOS]` tokens from the target tokenizer\n",
        "#   2. Compute encoder output for the source sequence\n",
        "#   3. Initialize decoder input with `[SOS]`\n",
        "#   4. Loop until `max_len` is reached or `[EOS]` is generated:\n",
        "#      - Create a causal mask for the decoder input\n",
        "#      - Compute decoder output using encoder output and masks\n",
        "#      - Apply the projection layer to get probabilities for the next token\n",
        "#      - Select the token with the highest probability and append it to the decoder input\n",
        "#      - Break the loop if `[EOS]` is generated\n",
        "#   5. Return the generated sequence of tokens\n",
        "\n",
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_id = tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_id = tokenizer_tgt.token_to_id('[EOS]')\n",
        "    enc_output = model.encode(source.to(device), source_mask.to(device))\n",
        "    ys = torch.tensor([[sos_id]], dtype=torch.long, device=device)\n",
        "    for _ in range(max_len):\n",
        "        tgt_mask = (ys != tokenizer_tgt.token_to_id('[PAD]')).unsqueeze(1).unsqueeze(2)\n",
        "        size = ys.size(1)\n",
        "        no_look = casual_mask(size).to(device)\n",
        "        tgt_mask = tgt_mask & no_look\n",
        "        dec_output = model.decode(ys, enc_output, source_mask.to(device), tgt_mask)\n",
        "        prob = model.project(dec_output[:, -1])\n",
        "        next_word = torch.argmax(prob, dim=-1)\n",
        "        ys = torch.cat([ys, next_word.unsqueeze(0)], dim=1)\n",
        "        if next_word.item() == eos_id:\n",
        "            break\n",
        "    return ys[0].cpu().numpy()\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "z1rzcAkpv8Ew",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:45.020144Z",
          "iopub.execute_input": "2025-01-17T01:36:45.020381Z",
          "iopub.status.idle": "2025-01-17T01:36:45.037789Z",
          "shell.execute_reply.started": "2025-01-17T01:36:45.020346Z",
          "shell.execute_reply": "2025-01-17T01:36:45.037098Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `run_validation` function to evaluate the model on the validation dataset\n",
        "# - Accept parameters:\n",
        "#   1. `model`: Trained Transformer model\n",
        "#   2. `validation_ds`: Validation dataset\n",
        "#   3. `tokenizer_src` and `tokenizer_tgt`: Tokenizers for source and target languages\n",
        "#   4. `max_len`: Maximum sequence length for decoding\n",
        "#   5. `device`: Device to run the computation (e.g., CPU or GPU)\n",
        "#   6. `print_msg`: Function for displaying output messages\n",
        "#   7. `global_state`: Optional global state for tracking progress\n",
        "#   8. `writer`: Optional logging writer (e.g., TensorBoard)\n",
        "#   9. `num_examples`: Number of examples to process per run (default: 2)\n",
        "\n",
        "# - Steps:\n",
        "#   1. Set the model to evaluation mode\n",
        "#   2. Initialize a counter to track the number of processed examples\n",
        "#   3. Define a fixed console width for printed messages\n",
        "#   4. Iterate through the validation dataset:\n",
        "#      - Retrieve `encoder_input` and `encoder_mask` and move them to the specified device\n",
        "#      - Ensure batch size is 1 for validation\n",
        "#      - Use `greedy_decode` to generate the model's predictions\n",
        "#      - Decode the model's output into human-readable text\n",
        "#      - Print source, target, and predicted text using `print_msg`\n",
        "#      - Break the loop after processing the specified number of examples (`num_examples`)\n",
        "#   5. Ensure no gradients are computed during evaluation\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state=None, writer=None, num_examples=2):\n",
        "    model.eval()\n",
        "    pad_id_src = tokenizer_src.token_to_id('[PAD]')\n",
        "    count = 0\n",
        "    console_width = 80\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            encoder_input = batch['encoder_input'].unsqueeze(0).to(device)\n",
        "            encoder_mask = (encoder_input != pad_id_src).unsqueeze(1).unsqueeze(2)\n",
        "            pred_tokens = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "            pred_text = tokenizer_tgt.decode(pred_tokens.tolist())\n",
        "            src_text = batch['src_text']\n",
        "            tgt_text = batch['tgt_text']\n",
        "            print_msg(f\"SRC: {src_text}\".ljust(console_width))\n",
        "            print_msg(f\"TGT: {tgt_text}\".ljust(console_width))\n",
        "            print_msg(f\"PRD: {pred_text}\".ljust(console_width))\n",
        "\n",
        "            count += 1\n",
        "            if count >= num_examples:\n",
        "                break\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "iF7v9L0owcLT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:45.038468Z",
          "iopub.execute_input": "2025-01-17T01:36:45.038657Z",
          "iopub.status.idle": "2025-01-17T01:36:45.056164Z",
          "shell.execute_reply.started": "2025-01-17T01:36:45.038641Z",
          "shell.execute_reply": "2025-01-17T01:36:45.055408Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 13: Training Loop"
      ],
      "metadata": {
        "id": "qw3nykKxwkIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We are ready to train our Transformer model on the OpusBook dataset for the English to Italian translation task.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We first start by defining the <code>get_model</code> function to load the model by calling the <code>build_transformer</code> function we have previously defined. This function uses the <code>config</code> dictionary to set a few parameters.</p>"
      ],
      "metadata": {
        "id": "az_Kwq4Zqr_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `get_model` function to initialize a Transformer model\n",
        "# - Accept parameters:\n",
        "#   1. `config`: Configuration dictionary with model settings\n",
        "#   2. `vocab_src_len`: Length of the source language vocabulary\n",
        "#   3. `vocab_tgt_len`: Length of the target language vocabulary\n",
        "\n",
        "# - Use the `build_transformer` function to:\n",
        "#   1. Create a Transformer model\n",
        "#   2. Pass the source and target vocabulary lengths\n",
        "#   3. Set sequence length (`seq_len`) and embedding dimensionality (`d_model`) from `config`\n",
        "\n",
        "# - Return the initialized model\n",
        "\n",
        "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
        "    model = build_transformer(\n",
        "        src_vocab_size=vocab_src_len,\n",
        "        tgt_vocab_size=vocab_tgt_len,\n",
        "        src_seq_len=config['seq_len'],\n",
        "        tgt_seq_len=config['seq_len'],\n",
        "        d_model=config['d_model']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "7QMn1BULwnBl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:45.058810Z",
          "iopub.execute_input": "2025-01-17T01:36:45.059021Z",
          "iopub.status.idle": "2025-01-17T01:36:45.073063Z",
          "shell.execute_reply.started": "2025-01-17T01:36:45.058997Z",
          "shell.execute_reply": "2025-01-17T01:36:45.072241Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">I have mentioned the <code>config</code> dictionary several times throughout this notebook. Now, it is time to create it.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the following cell, we will define two functions to configure our model and the training process.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>get_config</code> function, we define crucial parameters for the training process. <code>batch_size</code> for the number of training examples used in one iteration, <code>num_epochs</code> as the number of times the entire dataset is passed forward and backward through the Transformer, <code>lr</code> as the learning rate for the optimizer, etc. We will also finally define the pairs from the OpusBook dataset, <code>'lang_src': 'en'</code> for selecting English as the source language and <code>'lang_tgt': 'it'</code> for selecting Italian as the target language.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>get_weights_file_path</code> function constructs the file path for saving or loading model weights for any specific epoch.</p>"
      ],
      "metadata": {
        "id": "Ord2DlVkqr_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `get_config` function to return a dictionary of settings for building and training the Transformer model:\n",
        "#   1. `batch_size`: Number of samples per training batch\n",
        "#   2. `num_epochs`: Total training epochs\n",
        "#   3. `lr`: Learning rate for optimization\n",
        "#   4. `seq_len`: Maximum sequence length for tokens\n",
        "#   5. `d_model`: Dimensionality of embeddings (e.g., 512)\n",
        "#   6. `lang_src` and `lang_tgt`: Source and target languages\n",
        "#   7. `model_folder`: Folder to save model weights\n",
        "#   8. `model_basename`: Base name for model files\n",
        "#   9. `preload`: Option to preload a model (default: None)\n",
        "#   10. `tokenizer_file`: Filename pattern for saving tokenizers\n",
        "#   11. `experiment_name`: Name of the experiment for logging\n",
        "\n",
        "# - Define `get_weights_file_path` to construct a file path for saving/retrieving model weights:\n",
        "#   1. Accept `config` dictionary and `epoch` string as parameters\n",
        "#   2. Retrieve `model_folder` and `model_basename` from `config`\n",
        "#   3. Construct the filename with the base name and epoch\n",
        "#   4. Combine the current directory, model folder, and filename to return the full path\n",
        "\n",
        "def get_config():\n",
        "    return {\n",
        "        'batch_size': 32,\n",
        "        'num_epochs': 30,\n",
        "        'lr': 5e-4,\n",
        "        'seq_len': 64,\n",
        "        'd_model': 512,\n",
        "        'lang_src': 'en',\n",
        "        'lang_tgt': 'it',\n",
        "        'model_folder': 'checkpoints',\n",
        "        'model_basename': 'transformer',\n",
        "        'preload': None,\n",
        "        'tokenizer_file': 'tokenizer_{lang}.json',\n",
        "        'experiment_name': 'en-it'\n",
        "    }\n",
        "\n",
        "def get_weights_file_path(config, epoch):\n",
        "    model_folder = Path(config['model_folder'])\n",
        "    model_folder.mkdir(parents=True, exist_ok=True)\n",
        "    filename = f\"{config['model_basename']}_{epoch}.pth\"\n",
        "    return str(model_folder / filename)\n",
        "\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "gXt82CejxeHZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:45.074016Z",
          "iopub.execute_input": "2025-01-17T01:36:45.074268Z",
          "iopub.status.idle": "2025-01-17T01:36:45.081366Z",
          "shell.execute_reply.started": "2025-01-17T01:36:45.074249Z",
          "shell.execute_reply": "2025-01-17T01:36:45.080622Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We finally define our last function, <code>train_model</code>, which takes the <code>config</code> arguments as input. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In this function, we will set everything up for the training. We will load the model and its necessary components onto the GPU for faster training, set the <code>Adam</code> optimizer, and configure the <code>CrossEntropyLoss</code> function to compute the differences between the translations output by the model and the reference translations from the dataset. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Every loop necessary for iterating over the training batches, performing backpropagation, and computing the gradients is in this function. We will also use it to run the validation function and save the current state of the model.</p>"
      ],
      "metadata": {
        "id": "Qw7SjmrDqr_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n",
        "\n",
        "# - Define a `train_model` function to train a Transformer model\n",
        "# - Steps:\n",
        "#   1. Set up the device (GPU or CPU) for training\n",
        "#   2. Create a directory to store model weights\n",
        "#   3. Retrieve dataloaders and tokenizers for source and target languages using `get_ds`\n",
        "#   4. Initialize the Transformer model using `get_model` and move it to the specified device\n",
        "#   5. Set up TensorBoard for logging training metrics\n",
        "#   6. Configure the Adam optimizer with learning rate and epsilon from `config`\n",
        "#   7. If a pre-trained model exists:\n",
        "#      - Load the model, optimizer state, and global step\n",
        "#      - Set the starting epoch for resuming training\n",
        "#   8. Define a cross-entropy loss function:\n",
        "#      - Ignore padding tokens\n",
        "#      - Apply label smoothing to prevent overfitting\n",
        "#   9. Start training loop:\n",
        "#      - Iterate over epochs from the initial epoch to `config['num_epochs']`\n",
        "#      - For each batch in the training dataloader:\n",
        "#         - Set model to training mode\n",
        "#         - Move input data, masks, and labels to the device\n",
        "#         - Pass data through the encoder, decoder, and projection layer\n",
        "#         - Compute loss between model predictions and labels\n",
        "#         - Log training loss to TensorBoard\n",
        "#         - Perform backpropagation and update model parameters\n",
        "#         - Clear gradients for the next batch\n",
        "#         - Increment global step counter\n",
        "#      - After each epoch, run validation using `run_validation`\n",
        "#      - Save the current model state, optimizer state, and global step\n",
        "#   10. Save model weights after each epoch\n",
        "\n",
        "def train_model(config):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    Path(config['model_folder']).mkdir(parents=True, exist_ok=True)\n",
        "    train_loader, val_loader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
        "    model = get_model(config, vocab_src_len=tokenizer_src.get_vocab_size(), vocab_tgt_len=tokenizer_tgt.get_vocab_size()).to(device)\n",
        "    writer = SummaryWriter(log_dir=f\"runs/{config['experiment_name']}\")\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "    global_step = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    if config['preload']:\n",
        "        checkpoint = torch.load(config['preload'])\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        global_step = checkpoint['global_step']\n",
        "        start_epoch = checkpoint['epoch']\n",
        "\n",
        "    pad_id = tokenizer_tgt.token_to_id('[PAD]')\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=0.1)\n",
        "\n",
        "    for epoch in range(start_epoch, config['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']}\"):\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            decoder_input = batch['decoder_input'].to(device)\n",
        "            label = batch['label'].to(device)\n",
        "\n",
        "            encoder_mask = (encoder_input != pad_id).unsqueeze(1).unsqueeze(2)\n",
        "            seq_len = decoder_input.size(1)\n",
        "            dec_pad_mask = (decoder_input != pad_id).unsqueeze(1).unsqueeze(2)\n",
        "            no_look = casual_mask(seq_len).to(device).unsqueeze(0).unsqueeze(1)\n",
        "            decoder_mask = dec_pad_mask & no_look\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            enc_output = model.encode(encoder_input, encoder_mask)\n",
        "            dec_output = model.decode(decoder_input, enc_output, encoder_mask, decoder_mask)\n",
        "            logits = model.project(dec_output)\n",
        "\n",
        "            loss = criterion(logits.reshape(-1, logits.size(-1)), label.reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = logits.argmax(dim=-1)\n",
        "                mask = (label != pad_id)\n",
        "                num_tokens = mask.sum()\n",
        "                num_correct = (preds[mask] == label[mask]).sum()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += num_correct.item()\n",
        "            total_tokens += num_tokens.item()\n",
        "\n",
        "            writer.add_scalar(\"Loss/train\", loss.item(), global_step)\n",
        "            global_step += 1\n",
        "\n",
        "        epoch_loss = total_loss / len(train_loader)\n",
        "        epoch_accuracy = (total_correct / total_tokens) if total_tokens > 0 else 0\n",
        "\n",
        "        print(f\"End of Epoch {epoch+1}/{config['num_epochs']}, \"\n",
        "              f\"Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "\n",
        "        writer.add_scalar(\"EpochLoss/train\", epoch_loss, epoch)\n",
        "        writer.add_scalar(\"EpochAccuracy/train\", epoch_accuracy, epoch)\n",
        "\n",
        "        run_validation(\n",
        "            model=model,\n",
        "            validation_ds=val_loader,\n",
        "            tokenizer_src=tokenizer_src,\n",
        "            tokenizer_tgt=tokenizer_tgt,\n",
        "            max_len=config['seq_len'],\n",
        "            device=device,\n",
        "            print_msg=print,\n",
        "            writer=writer,\n",
        "            num_examples=2\n",
        "        )\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, get_weights_file_path(config, epoch+1))\n",
        "\n",
        "    writer.close()\n",
        "######################  TODO  ########################\n",
        "######################  TODO  ########################\n"
      ],
      "metadata": {
        "id": "2qK9wAjRxoDQ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:45.082193Z",
          "iopub.execute_input": "2025-01-17T01:36:45.082432Z",
          "iopub.status.idle": "2025-01-17T01:36:45.104139Z",
          "shell.execute_reply.started": "2025-01-17T01:36:45.082391Z",
          "shell.execute_reply": "2025-01-17T01:36:45.103391Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now train the model!"
      ],
      "metadata": {
        "id": "nrMmfyi8xrXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First Try:**\n",
        "\n",
        "I used T4 in colab with Learning Rate = 1e-4"
      ],
      "metadata": {
        "id": "nQm5kX7IQUfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings('ignore')\n",
        "    config = get_config()\n",
        "    train_model(config)"
      ],
      "metadata": {
        "id": "28425EYaxrsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1815bcbc-1410-4e2a-9cc2-522b2c8b95ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max source length: 309\n",
            "Max target length: 274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 910/910 [04:14<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: — Ma il mio mio mio , e non si .                                           \n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: — Ma , ma , e il suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 910/910 [04:14<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Il signor Rochester era un ’ altra volta , ma si .                         \n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: — In quel momento , che era stata un ’ altra volta , ma non si .           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 910/910 [04:13<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: La sua vita , che si , e , a casa .                                        \n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: — E il suo padre , che si , e il suo padre .                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 910/910 [04:14<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Egli si , e , dopo aver detto , si mise a , e , si mise a parlare di nuovo .\n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: Non c ’ era nulla di nuovo , ma il suo padre si .                          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 910/910 [04:13<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Egli si , e , per la sua opinione , si fermò a sé , e si mise a parlare di nuovo .\n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: Non si , e , come un ’ altra volta , si , si , e la sua opinione , si .    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 910/910 [04:13<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Egli si avvicinò alla mente , e , per vedere i suoi pensieri , si mise a guardare il suo posto .\n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: Non c ’ era nulla di straordinario , che si di nuovo , e di nuovo , per un po ’ di cui si , di nuovo a lungo , si .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 910/910 [04:13<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Egli si , e , per un tratto , si rivolse a sé :                            \n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: Non c ’ era nulla di straordinario , che la sua opinione si , e la quale si di nuovo , si di nuovo .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 910/910 [04:14<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Egli si , e , per quanto si , si , si , si di nuovo a sé e di nuovo , per essere messo in modo di nuovo .\n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: Non c ’ è nulla di straordinario , che un ’ altra cosa , e la di nuovo , si dalla stessa maniera di nuovo per un po ’ di cui si .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 910/910 [04:14<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Si sentiva che , se ne fosse stato , si era messo a guardare , e si sentiva in modo di nuovo a disagio .\n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: Non c ’ era nulla di straordinario , che si di nuovo il suo posto , e il quale si trovava in una volta , si era messo a ridere di nuovo verso la sua statura , che non si trovava più nulla .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 910/910 [04:15<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ['Vronsky stopped and asked him straight out:']                            \n",
            "TGT: ['Vronskij si fermò e chiese franco:']                                     \n",
            "PRD: Si accorse che , per lui , si avvicinava a sé , si era fatto di nuovo , e si mise a guardare il suo sguardo .\n",
            "SRC: ['\"What a beautiful room!\" I exclaimed, as I looked round; for I had never before seen any half so imposing.']\n",
            "TGT: [\"— Che bella stanza! — esclamai, guardando intorno. — È la sala da pranzo; ho aperto la finestra per farvi entrare un po' d'aria.\"]\n",
            "PRD: Non c ’ era nulla di straordinario , che la sua fantasia era stata in mente , si era messa a guardare dalla sua maniera di , e di nuovo nel momento in cui si era le cose .\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second Try:**\n",
        "\n",
        "I used T4 x2 in Kaggle with Learning rate = 5e-4\n",
        "\n",
        "Running terminated because of Net2.Sharif disconnection."
      ],
      "metadata": {
        "id": "3tiz-BIoQozi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings('ignore')\n",
        "    config = get_config()\n",
        "    train_model(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vDMIXvIdHsR",
        "outputId": "52d684f7-9ddc-4be6-9762-a62c98211e3a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T00:25:42.984651Z",
          "iopub.execute_input": "2025-01-17T00:25:42.984969Z",
          "execution_failed": "2025-01-17T01:28:08.149Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Max source length: 309\nMax target length: 274\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 1/30: 100%|██████████| 910/910 [04:28<00:00,  3.39it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 1/30, Loss: 6.3059, Accuracy: 0.1617\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — Ma non si , e non si , e non si .                                        \nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — Ma non si , ma non si .                                                  \n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 2/30, Loss: 5.6614, Accuracy: 0.2065\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — Ma non c ’ era un , ma non c ’ era un po ’ di .                          \nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — Ma non c ’ è nulla di , ma non c ’ è un di .                             \n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 3/30, Loss: 5.3708, Accuracy: 0.2294\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — Ma , come , come , come se ne , e , la sua vita .                        \nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — Non c ’ è nulla di , ma non è nulla di .                                 \n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 4/30, Loss: 5.1390, Accuracy: 0.2504\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — , , — disse , — ma , la mano , la sua .                                  \nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — , , , — disse , e la mano .                                              \n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 5/30, Loss: 4.9171, Accuracy: 0.2723\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — Il mio , , , e a lungo , , , a questo , .                                \nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — Il mio amico , che non ho mai fatto nulla , e che la , e la di .         \n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 6/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 6/30, Loss: 4.6885, Accuracy: 0.2954\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — Il mio , e il nostro , è vero , e la sua bellezza .                      \nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — Il mio amico , che ho fatto , e la mia parte è stata una volta che non si può esser buona .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 7/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 7/30, Loss: 4.4542, Accuracy: 0.3209\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: E qui , come al solito , si , si , si , e la stessa cosa .                 \nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — In questo momento , con la sua anima , la sua vita , la quale è passata .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 8/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 8/30, Loss: 4.2069, Accuracy: 0.3536\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — Il mio picchiare , — continuò , — è un ’ altra cosa , e poi mi pigli : è così , che non ci sarà mai più bella e buona , e ora ne .\nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — Il mio povero , — continuò , — e io mi , e poi mi di aver fatto bene la sua opera .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 9/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 9/30, Loss: 3.9568, Accuracy: 0.3936\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: Il solo argomento del lavoro si era comportato con straordinaria ansietà ; ma il resto era pronto a fuggire e si fermava a fuggire e .\nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — La mia prima opinione era una cosa reale , e la stessa cosa si a proposito di .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 10/30: 100%|██████████| 910/910 [04:37<00:00,  3.28it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 10/30, Loss: 3.7183, Accuracy: 0.4375\nSRC: ['And when out shooting, while he did not seem to be thinking at all, he again and again thought about the old peasant and his family, and felt as if the impression made on him called not only for his attention, but for the solution of some problem related thereto.']\nTGT: ['E a caccia, quando gli pareva di non pensare a nulla, che è che non è, di nuovo gli tornava in mente il vecchio con la sua famiglia, e la viva impressione che gli era rimasta sembrava esigesse attenzione non solo per se stessa, ma anche perché gli pareva si collegasse alla soluzione di un qualche cosa.']\nPRD: — L ’ ha intesa , signore , l ’ ha intesa , l ’ ha intesa , l ’ ha intesa , l ’ ultimo testimone , la .\nSRC: [\"'You must take me too!\"]                                                 \nTGT: ['— Prendete anche me con voi.']                                           \nPRD: — L ’ ho già guardato con cura , — continuò il figlio — e io non ho mai veduto il diritto di .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 11/30:  74%|███████▍  | 674/910 [03:25<01:11,  3.30it/s]",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Third Try:**\n",
        "\n",
        "I used GPU P100 in Kaggle with Learning rate = 5e-4\n",
        "\n",
        "And I reached to +0.80 Accuracy\n",
        "\n",
        "Running terminated because I fell sleep and my laptop turned off ..."
      ],
      "metadata": {
        "id": "3kdp_g0wRIML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings('ignore')\n",
        "    config = get_config()\n",
        "    train_model(config)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T01:36:45.104974Z",
          "iopub.execute_input": "2025-01-17T01:36:45.105251Z",
          "iopub.status.idle": "2025-01-17T02:39:41.915537Z",
          "shell.execute_reply.started": "2025-01-17T01:36:45.105223Z",
          "shell.execute_reply": "2025-01-17T02:39:41.913981Z"
        },
        "colab": {
          "referenced_widgets": [
            "147bbfd3e8984c0181685e4f898c06db",
            "6912ff621af34d9bacd4d77254a44402",
            "1c93c6ef84314b78843b9c7c73d691ef"
          ]
        },
        "id": "blV8kIeCPdYh",
        "outputId": "59964631-85fb-46e8-c28f-ee5de910ba37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "147bbfd3e8984c0181685e4f898c06db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/5.73M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6912ff621af34d9bacd4d77254a44402"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c93c6ef84314b78843b9c7c73d691ef"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Max source length: 309\nMax target length: 274\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 1/30: 100%|██████████| 910/910 [02:36<00:00,  5.83it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 1/30, Loss: 6.3029, Accuracy: 0.1633\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: E che la sua vita , e la sua vita , e la sua vita .                        \nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Levin , che la sua vita , e la sua vita , e la sua vita .                  \n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/30: 100%|██████████| 910/910 [02:35<00:00,  5.85it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 2/30, Loss: 5.6475, Accuracy: 0.2079\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Ma , come , e la mia vita , e la sua vita .                                \nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Levin non si era stato un ’ altra , ma che si fosse stato stato stato in camera .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/30: 100%|██████████| 910/910 [02:35<00:00,  5.85it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 3/30, Loss: 5.3631, Accuracy: 0.2303\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: il suo sguardo , e la mia vita , e la sua vita , e la sua vita , e la sua .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: E la signorina Scatcherd , che la sua vita era , e la sua vita , e la sua .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 4/30, Loss: 5.1249, Accuracy: 0.2527\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Io non aveva mai fatto nulla , e la sua opinione , e la sua opinione .     \nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: E , dopo aver fatto il tè , e la sua voce di cui aveva fatto un ’ altra volta , e che non si poteva fare .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 5/30, Loss: 4.8963, Accuracy: 0.2748\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: , e , come se lo , e la mano .                                             \nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Ma , come , per la sua disgrazia , si era messa a letto , e la sua amicizia non si poteva fare .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 6/30: 100%|██████████| 910/910 [02:34<00:00,  5.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 6/30, Loss: 4.6730, Accuracy: 0.2968\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Il suo sguardo era un uomo duro , che non aveva mai avuto il diritto di fare , e che si era fermato in piedi .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Anna si alzò in fretta e , dopo aver parlato , si rivolse a sé il suo sguardo con la sua attenzione .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 7/30: 100%|██████████| 910/910 [02:34<00:00,  5.91it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 7/30, Loss: 4.4403, Accuracy: 0.3225\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Mio padre , che era stato cambiato , e che non aveva nessuna importanza , e che si deve fare .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Vronskij , , e , , , , la mano , e si mise a .                             \n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 8/30: 100%|██████████| 910/910 [02:34<00:00,  5.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 8/30, Loss: 4.1998, Accuracy: 0.3545\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Levin , , , in sé , picchiando a terra , e a guardare il suo posto .       \nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Il sentimento di cui era stato fatto , secondo il solito , si mostrò le forme delle forme della mia opinione , e per quanto per il resto di cui si deve fare .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 9/30: 100%|██████████| 910/910 [02:34<00:00,  5.90it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 9/30, Loss: 3.9589, Accuracy: 0.3926\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: \" Sulle prime , che le , si a un tratto , che , e che la , sarà presto .   \nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Dar ’ ja Aleksandrovna , che , in quel momento , con la massima onestà , si ferma e .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 10/30: 100%|██████████| 910/910 [02:34<00:00,  5.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 10/30, Loss: 3.7226, Accuracy: 0.4364\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: \" Sulle prime non ho nulla , sono buone , specialmente una volta che si deve sperare , e non ha fatto nascere da bere il coraggio di .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: , , , , eius , eius , eius , eius , eius , eius , desiderò di non avere gusto per il posto di una persona .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 11/30: 100%|██████████| 910/910 [02:34<00:00,  5.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 11/30, Loss: 3.5035, Accuracy: 0.4791\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: E così , per la prima volta , si , si volse a guardare il polso e , la lingua , per non avere bisogno di un altro .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Dar ’ ja Aleksandrovna , sempre , allungata sulla sedia , e gli disse : — Sarà difficile male , tanto meglio , tanto più che non ha fatto per questo mondo ?\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 12/30: 100%|██████████| 910/910 [02:35<00:00,  5.85it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 12/30, Loss: 3.3066, Accuracy: 0.5193\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Un ’ altra , che era stato , , era il fornello , a prenderlo e a pensare che bisognava condurre la strada .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Dolly , che aveva indovinato in pieno la proposta di parentela , si trovava , e , dopo aver sospirato con cura , si affrettava a disagio .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 13/30: 100%|██████████| 910/910 [02:35<00:00,  5.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 13/30, Loss: 3.1320, Accuracy: 0.5573\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: \" , Dick , che tutto questo sarà , come il fatto in casa , non in un luogo , anche in un luogo , in un luogo , in generale .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Dar ’ ja Aleksandrovna , salutandolo , si in un modo che , dopo , si , si in un modo : il giudice , i due bambini , si .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 14/30: 100%|██████████| 910/910 [02:34<00:00,  5.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 14/30, Loss: 2.9768, Accuracy: 0.5910\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Un po ’ in quel luogo , al quale io ero a sedere sulla strada , e che in piedi sembrava un tale casi di cui si trattava o no .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: , Sigonin , e poi , per dir vero , quando si mise a pensare a tutta la gente che aveva sognato per il lavoro , e per l ’ aria non riuscì a nessuno l ’ aveva più .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 15/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 15/30, Loss: 2.8340, Accuracy: 0.6250\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Per l ’ amor di Dio , non c ’ era nulla da fare ; vi ringrazio molto , e poi il fatto che l ’ ha fatto bene o l ’ effetto delle persone più belle .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Anna , che , come direttore di banca , doveva essere , doveva essere il miglior mezzo di quello che doveva fare .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 16/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 16/30, Loss: 2.7114, Accuracy: 0.6535\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: — , , , , , , , , , ’ è vero che non può .                                 \nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: A quanto a lei , alla sua prima volta , si stendeva una specie d ’ uva che faceva con tanta disinvoltura e fatica , e che non battuta .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 17/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 17/30, Loss: 2.5960, Accuracy: 0.6825\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Una volta , in quel momento , era , a quanto sembra , si fosse fermata , e il fatto faceva piacere di .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: L ’ altra persona , che aveva incontrato da lui , Levin si era assaltato ; e da vero , invece , aveva dato uno sguardo di una volta , la propria , la baciò .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 18/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 18/30, Loss: 2.4976, Accuracy: 0.7076\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Era dominato da un lato , che era stato ferito , che era in piedi , un ’ occhiata al villaggio , mi portò qua e a domandare che cosa dovevo fare ?\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: — , Anna , — disse , — e tu non andrebbe più nulla a l ’ occasione per a un ’ occhiata .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 19/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 19/30, Loss: 2.4104, Accuracy: 0.7313\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Era come se avessi potuto capire , che in questo momento non era ancora morto , che un di quelle acque , senza aver il diritto di .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: A ogni modo , a vedersi , con le mani e i , le calze , con le spalle al loro , si fecero silenzio .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 20/30: 100%|██████████| 910/910 [02:34<00:00,  5.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 20/30, Loss: 2.3342, Accuracy: 0.7523\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: — , allora , come un tale lavoro , si può evitare un tale di gusto in una situazione tale che è possibile .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: È il fatto che perdei un gran tempo nel mio solo modo con lei , mentre così diceva il miglior modo da far cessare l ’ oppio .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 21/30: 100%|██████████| 910/910 [02:34<00:00,  5.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 21/30, Loss: 2.2643, Accuracy: 0.7715\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: — , ma a non giudicare , a quanto pare , alla stazione termale che vi sia la da noi stessi altri .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: Venne a parlare , a star ritto sul sofà , o no , per dargli il denaro ; ma non c ’ era alcuna parte , quanto tempo mi facessero piacere .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 22/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 22/30, Loss: 2.2050, Accuracy: 0.7887\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Il lavoro dei primi tempi del suo arrivo era un militare ; da altro che il loro aspetto , le sue , le appassionate , e i piccoli nella fretta .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: A volte , sedettero sui suoi riccioli d ’ anelli , lo stesso che e che non altro che lo , e che dovessero stare benissimo .\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 23/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 23/30, Loss: 2.1503, Accuracy: 0.8048\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Il conto dell ’ alba era così forte , e il mio bere , mentre si stava legato a gridare così come ad una volta abbia fatto il tempo di riflettere .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: A parte il bel tempo , con quello che era stato ferito . E , guardando il cervello , si sollevò il buon senso , così come un pasto portava il latte , la cosa sola mano a parte di chi ?\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 24/30: 100%|██████████| 910/910 [02:34<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "End of Epoch 24/30, Loss: 2.1001, Accuracy: 0.8196\nSRC: [\"'Just one advantage: I live in my own house, which is neither bought nor hired.\"]\nTGT: ['— L’unico vantaggio è che vivo a casa mia, non è roba comprata, né presa in affitto.']\nPRD: Il numero 12 era soddisfazione e più piccolo di quello di cui mi aveva trovata accanto a loro ; a loro si era ammalata , non mangiava né .\nSRC: [\"Dolly was glad when Anna came in and thereby put an end to Annushka's chatter.\"]\nTGT: ['Dolly fu contenta quando Anna entrò da lei e con la sua presenza fece cessare il chiacchierio di Annuška.']\nPRD: A volte , alla mia parte , non so se fosse bella o no , comunque fosse la cosa alcuna .\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data/1035: file write failed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-1a809b5eda61>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-9efbdedb9fab>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         torch.save({\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m             _save(\n\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:603] . unexpected pos 134578688 vs 134578576"
          ],
          "ename": "RuntimeError",
          "evalue": "[enforce fail at inline_container.cc:603] . unexpected pos 134578688 vs 134578576",
          "output_type": "error"
        }
      ],
      "execution_count": null
    }
  ]
}